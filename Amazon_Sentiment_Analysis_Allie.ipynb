{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import model_selection, naive_bayes\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('amazon-reviews.csv', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stuning even for the non-gamer: This sound tr...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The best soundtrack ever to anything.: I'm re...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Amazing!: This soundtrack is my favorite musi...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Excellent Soundtrack: I truly like this sound...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After H...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        label\n",
       "0   Stuning even for the non-gamer: This sound tr...  __label__2 \n",
       "1   The best soundtrack ever to anything.: I'm re...  __label__2 \n",
       "2   Amazing!: This soundtrack is my favorite musi...  __label__2 \n",
       "3   Excellent Soundtrack: I truly like this sound...  __label__2 \n",
       "4   Remember, Pull Your Jaw Off The Floor After H...  __label__2 "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clean_text(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texts are complete.\n"
     ]
    }
   ],
   "source": [
    "clean_texts = []\n",
    "i = 0\n",
    "for text in data.text:\n",
    "    clean_texts.append(clean_text(text))\n",
    "    data['text'][i] = clean_texts[i]\n",
    "    i+=1\n",
    "print(\"Texts are complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>stuning even non gamer sound track beautiful p...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>best soundtrack ever anything reading lot revi...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>amazing soundtrack favorite music time hands i...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excellent soundtrack truly like soundtrack enj...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>remember pull jaw floor hearing played game kn...</td>\n",
       "      <td>__label__2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text        label\n",
       "0  stuning even non gamer sound track beautiful p...  __label__2 \n",
       "1  best soundtrack ever anything reading lot revi...  __label__2 \n",
       "2  amazing soundtrack favorite music time hands i...  __label__2 \n",
       "3  excellent soundtrack truly like soundtrack enj...  __label__2 \n",
       "4  remember pull jaw floor hearing played game kn...  __label__2 "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split dataset\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# train-test split\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(data.text, data.label) \n",
    "\n",
    "# label encode the target \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}') \n",
    "count_vect.fit(data.text) # regexp selects tokens of 1 or more alphanumeric characters\n",
    "\n",
    "xall_count = count_vect.transform(data.text)\n",
    "xtrain_count = count_vect.transform(x_train)\n",
    "xtest_count = count_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# word-level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(data.text)\n",
    "xtrain_tfidf = tfidf_vect.transform(x_train)\n",
    "xtest_tfidf = tfidf_vect.transform(x_test)\n",
    "\n",
    "# ngram-level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2, 3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(data.text) # measures bi-grams and tri-grams\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.transform(x_train)\n",
    "xtest_tfidf_ngram = tfidf_vect_ngram.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word 0</th>\n",
       "      <th>Word 1</th>\n",
       "      <th>Word 2</th>\n",
       "      <th>Word 3</th>\n",
       "      <th>Word 4</th>\n",
       "      <th>Word 5</th>\n",
       "      <th>Word 6</th>\n",
       "      <th>Word 7</th>\n",
       "      <th>Word 8</th>\n",
       "      <th>Word 9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Topic 0</th>\n",
       "      <td>battery</td>\n",
       "      <td>camera</td>\n",
       "      <td>power</td>\n",
       "      <td>version</td>\n",
       "      <td>tape</td>\n",
       "      <td>charger</td>\n",
       "      <td>charge</td>\n",
       "      <td>apple</td>\n",
       "      <td>adapter</td>\n",
       "      <td>plug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 1</th>\n",
       "      <td>cd</td>\n",
       "      <td>music</td>\n",
       "      <td>album</td>\n",
       "      <td>songs</td>\n",
       "      <td>song</td>\n",
       "      <td>tracks</td>\n",
       "      <td>sound</td>\n",
       "      <td>blue</td>\n",
       "      <td>rice</td>\n",
       "      <td>cable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 2</th>\n",
       "      <td>boot</td>\n",
       "      <td>metal</td>\n",
       "      <td>ugly</td>\n",
       "      <td>bar</td>\n",
       "      <td>sheets</td>\n",
       "      <td>results</td>\n",
       "      <td>email</td>\n",
       "      <td>contact</td>\n",
       "      <td>cooker</td>\n",
       "      <td>coyote</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 3</th>\n",
       "      <td>air</td>\n",
       "      <td>small</td>\n",
       "      <td>apart</td>\n",
       "      <td>stopped</td>\n",
       "      <td>keeps</td>\n",
       "      <td>pump</td>\n",
       "      <td>shipped</td>\n",
       "      <td>local</td>\n",
       "      <td>fast</td>\n",
       "      <td>drive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 4</th>\n",
       "      <td>junk</td>\n",
       "      <td>la</td>\n",
       "      <td>jack</td>\n",
       "      <td>de</td>\n",
       "      <td>windows</td>\n",
       "      <td>built</td>\n",
       "      <td>mac</td>\n",
       "      <td>card</td>\n",
       "      <td>scanner</td>\n",
       "      <td>twist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 5</th>\n",
       "      <td>american</td>\n",
       "      <td>printer</td>\n",
       "      <td>brother</td>\n",
       "      <td>hopkins</td>\n",
       "      <td>haunting</td>\n",
       "      <td>dummy</td>\n",
       "      <td>america</td>\n",
       "      <td>print</td>\n",
       "      <td>economics</td>\n",
       "      <td>fats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 6</th>\n",
       "      <td>book</td>\n",
       "      <td>read</td>\n",
       "      <td>one</td>\n",
       "      <td>would</td>\n",
       "      <td>books</td>\n",
       "      <td>like</td>\n",
       "      <td>reading</td>\n",
       "      <td>story</td>\n",
       "      <td>people</td>\n",
       "      <td>could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 7</th>\n",
       "      <td>movie</td>\n",
       "      <td>one</td>\n",
       "      <td>film</td>\n",
       "      <td>like</td>\n",
       "      <td>great</td>\n",
       "      <td>good</td>\n",
       "      <td>dvd</td>\n",
       "      <td>album</td>\n",
       "      <td>music</td>\n",
       "      <td>best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 8</th>\n",
       "      <td>would</td>\n",
       "      <td>one</td>\n",
       "      <td>get</td>\n",
       "      <td>product</td>\n",
       "      <td>buy</td>\n",
       "      <td>great</td>\n",
       "      <td>good</td>\n",
       "      <td>bought</td>\n",
       "      <td>money</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Topic 9</th>\n",
       "      <td>book</td>\n",
       "      <td>great</td>\n",
       "      <td>good</td>\n",
       "      <td>one</td>\n",
       "      <td>love</td>\n",
       "      <td>story</td>\n",
       "      <td>really</td>\n",
       "      <td>like</td>\n",
       "      <td>better</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word 0   Word 1   Word 2   Word 3    Word 4   Word 5   Word 6  \\\n",
       "Topic 0   battery   camera    power  version      tape  charger   charge   \n",
       "Topic 1        cd    music    album    songs      song   tracks    sound   \n",
       "Topic 2      boot    metal     ugly      bar    sheets  results    email   \n",
       "Topic 3       air    small    apart  stopped     keeps     pump  shipped   \n",
       "Topic 4      junk       la     jack       de   windows    built      mac   \n",
       "Topic 5  american  printer  brother  hopkins  haunting    dummy  america   \n",
       "Topic 6      book     read      one    would     books     like  reading   \n",
       "Topic 7     movie      one     film     like     great     good      dvd   \n",
       "Topic 8     would      one      get  product       buy    great     good   \n",
       "Topic 9      book    great     good      one      love    story   really   \n",
       "\n",
       "          Word 7     Word 8  Word 9  \n",
       "Topic 0    apple    adapter    plug  \n",
       "Topic 1     blue       rice   cable  \n",
       "Topic 2  contact     cooker  coyote  \n",
       "Topic 3    local       fast   drive  \n",
       "Topic 4     card    scanner   twist  \n",
       "Topic 5    print  economics    fats  \n",
       "Topic 6    story     people   could  \n",
       "Topic 7    album      music    best  \n",
       "Topic 8   bought      money    like  \n",
       "Topic 9     like     better    time  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Latent Dirichlet Allocation model (with online variational Bayes algorithm)\n",
    "from sklearn import decomposition\n",
    "import numpy as np\n",
    "\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=10, learning_method='online', max_iter=100)\n",
    "lda_fit = lda_model.fit_transform(xall_count)\n",
    "topics = lda_model.components_ \n",
    "vocab = count_vect.get_feature_names()\n",
    "\n",
    "# top keywords for each topic\n",
    "n_words = 10\n",
    "vocab = count_vect.get_feature_names()\n",
    "keywords = np.array(vocab)\n",
    "topic_keywords = []\n",
    "for topic_weights in topics:\n",
    "    top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "    topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "df_topic_kw = pd.DataFrame(topic_keywords)\n",
    "df_topic_kw.columns = ['Word '+str(i) for i in range(df_topic_kw.shape[1])]\n",
    "df_topic_kw.index = ['Topic '+str(i) for i in range(df_topic_kw.shape[0])]\n",
    "df_topic_kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic 0</th>\n",
       "      <th>Topic 1</th>\n",
       "      <th>Topic 2</th>\n",
       "      <th>Topic 3</th>\n",
       "      <th>Topic 4</th>\n",
       "      <th>Topic 5</th>\n",
       "      <th>Topic 6</th>\n",
       "      <th>Topic 7</th>\n",
       "      <th>Topic 8</th>\n",
       "      <th>Topic 9</th>\n",
       "      <th>dominant_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.04</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.41</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.78</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Topic 0  Topic 1  Topic 2  Topic 3  Topic 4  Topic 5  Topic 6  Topic 7  \\\n",
       "0      0.0     0.04     0.00      0.0     0.00     0.00     0.60     0.35   \n",
       "1      0.0     0.00     0.00      0.0     0.00     0.00     0.27     0.52   \n",
       "2      0.0     0.00     0.00      0.0     0.00     0.02     0.09     0.57   \n",
       "3      0.0     0.00     0.00      0.0     0.28     0.00     0.00     0.63   \n",
       "4      0.0     0.00     0.00      0.0     0.00     0.00     0.00     0.95   \n",
       "5      0.0     0.00     0.00      0.0     0.00     0.25     0.00     0.33   \n",
       "6      0.0     0.00     0.00      0.0     0.00     0.01     0.84     0.00   \n",
       "7      0.0     0.00     0.00      0.0     0.03     0.00     0.17     0.00   \n",
       "8      0.0     0.00     0.15      0.0     0.02     0.09     0.38     0.00   \n",
       "9      0.0     0.00     0.00      0.0     0.07     0.00     0.46     0.00   \n",
       "\n",
       "   Topic 8  Topic 9  dominant_topic  \n",
       "0     0.00     0.00               6  \n",
       "1     0.19     0.00               7  \n",
       "2     0.31     0.00               7  \n",
       "3     0.08     0.00               7  \n",
       "4     0.00     0.04               7  \n",
       "5     0.00     0.41               9  \n",
       "6     0.14     0.00               6  \n",
       "7     0.00     0.78               9  \n",
       "8     0.00     0.34               6  \n",
       "9     0.00     0.45               6  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dominant topic for each matrix\n",
    "topic_names = ['Topic ' + str(i) for i in range(lda_model.n_components)]\n",
    "df_doctop = pd.DataFrame(np.round(lda_fit, 2), columns=topic_names, index=data.index)\n",
    "dominant_topic = np.argmax(df_doctop.values, axis=1)\n",
    "df_doctop['dominant_topic'] = dominant_topic \n",
    "df_doctop.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in texts: 31545\n"
     ]
    }
   ],
   "source": [
    "data2 = data\n",
    "# coll2apse texts into a set\n",
    "data = data2.text.map(word_tokenize).values\n",
    "total_vocabulary = set(word for line in data for word in line)\n",
    "print('Unique tokens in texts: {}'.format(len(total_vocabulary)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word embedding\n",
    "# ! pip3 install gensim\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "w2v_model = Word2Vec(data, window=5, min_count=1, workers=4)\n",
    "w2v_model.train(data, total_examples=w2v_model.corpus_count, epochs=10)\n",
    "word_vectors = w2v_model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Words Most Similar to Amazon:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('com', 0.8505464196205139),\n",
       " ('sale', 0.8436679244041443),\n",
       " ('purchase', 0.8381311893463135),\n",
       " ('refund', 0.836225688457489),\n",
       " ('vendor', 0.8354429602622986),\n",
       " ('return', 0.8338057398796082),\n",
       " ('seller', 0.8285685777664185),\n",
       " ('mail', 0.8234552145004272),\n",
       " ('offered', 0.8066745400428772),\n",
       " ('company', 0.8025359511375427)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Words Most Similar to Amazon:')\n",
    "display(word_vectors.most_similar('amazon'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model wrapper function\n",
    "from sklearn import metrics\n",
    "\n",
    "def train_model(classifier, train_features, label, test_features):\n",
    "    # fit the training data on classifier\n",
    "    classifier.fit(train_features, label)\n",
    "    \n",
    "    # predict testing data labels\n",
    "    predictions = classifier.predict(test_features)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Naive Bayes] Count Vectors Accuracy: 0.838\n",
      "[Naive Bayes] Word-Level TF-IDF Accuracy: 0.845\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "# Count Vectors\n",
    "nb_cv = train_model(naive_bayes.MultinomialNB(), xtrain_count, y_train, xtest_count)\n",
    "print(\"[Naive Bayes] Count Vectors Accuracy:\", round(nb_cv, 3))\n",
    "\n",
    "# Word-Level TF-IDF Vectors\n",
    "nb_wl = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"[Naive Bayes] Word-Level TF-IDF Accuracy:\", round(nb_wl, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Logistic Regression] Count Vectors Accuracy: 0.848\n",
      "[Logistic Regression] Word-Level TF-IDF Accuracy: 0.853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arthu\\Efrei\\DATA_VISUALIZATION\\cours2\\st_app\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Count Vectors\n",
    "lr_cv = train_model(linear_model.LogisticRegression(), xtrain_count, y_train, xtest_count)\n",
    "print(\"[Logistic Regression] Count Vectors Accuracy:\", round(lr_cv, 3))\n",
    "\n",
    "# Word-Level TF-IDF Vectors\n",
    "lr_wl = train_model(linear_model.LogisticRegression(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"[Logistic Regression] Word-Level TF-IDF Accuracy:\", round(lr_wl, 3))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
